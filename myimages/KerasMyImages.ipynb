{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Website that I got this idea from: \n",
    "\n",
    "http://learnandshare645.blogspot.com/2016/06/feeding-your-own-data-set-into-cnn.html - reading in a directory of files to do the keras on.\n",
    " \n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html - creating a new sample of pictures from the old ones.\n",
    "\n",
    "https://www.youtube.com/watch?v=LhEMXbjGV_4 - Preprocess images using keras.preprocessing.image\n",
    "\n",
    "https://www.youtube.com/watch?v=daovGOlMbT4&index=12&list=PLZbbT5o_s2xrwRnXk_yCPtnqqo4_u2YGL - Training the Keras model with fit_generator and batches\n",
    "\n",
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D as c2d\n",
    "from keras.layers.convolutional import MaxPooling2D as m2d\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator as idg\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "#import theano\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 200, 200\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out how to read in my own images\n",
    "1. get the current path to the images\n",
    "2. for each directory, read in the files\n",
    "3. Convert the files to read into the keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trng_path = os.getcwd()+'/myimages/catsndogs/train'\n",
    "test_path = os.getcwd()+'/myimages/catsndogs/test'\n",
    "\n",
    "train_batch = idg().flow_from_directory(trng_path, target_size=(256, 256), color_mode='rgb', classes=['dogs','cats'], class_mode='categorical', batch_size=50)\n",
    "test_batch = idg().flow_from_directory(test_path, target_size=(256, 256), color_mode='rgb', classes=['dogs','cats'], class_mode='categorical', batch_size=20\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if(type(ims[0])) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if(ims.shape[-1] !=3):\n",
    "            ims=ims.transpose((0,2,3,1))\n",
    "    f=plt.figure(figsize=figsize)\n",
    "    cols= len(ims)//rows if len(ims)%2 ==0 else len(ims)//rows+1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows,cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if(titles is not None):\n",
    "            sp.set_title(titles[i], fontsize=12)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs,labels = next(train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(imgs,titles = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(c2d(filters=32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(256, 256, 3)))\n",
    "#model.add(Flatten())\n",
    "model.add(m2d(pool_size=4))\n",
    "#model.add(Dense(256*256, activation=\"relu\", input_shape=(256*256,)))\n",
    "#model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_input = model.layers[0]\n",
    "print(layer_input.get_weights()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model = model.fit_generator(train_batch, steps_per_epoch=1, validation_data=test_batch, validation_steps =1, epochs=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path1 = os.getcwd()+'/myimages/catsndogs'\n",
    "path2 = os.getcwd()+'/myimagesresized/catsndogs'\n",
    "listing = os.listdir(path1) \n",
    "#print(listing)\n",
    "\n",
    "for directory in listing:\n",
    "    print(\"directory is \" + directory)\n",
    "    if(directory == '.ipynb_checkpoints'):\n",
    "        continue\n",
    "    dirname = (path1+'/'+directory)\n",
    "    dirfiles = os.listdir(dirname)\n",
    "    for subdir in dirfiles:\n",
    "        print(\"subdir is \" + subdir)\n",
    "        if(subdir == '.ipynb_checkpoints'):\n",
    "            continue\n",
    "        subdirname = (path1+'/'+directory+'/'+subdir)\n",
    "        print(subdirname)\n",
    "        subdirname = os.listdir(subdirname)\n",
    "        #print(dirfiles)\n",
    "        for file in subdirname:\n",
    "            if(file == '.ipynb_checkpoints'):\n",
    "                continue\n",
    "            im = Image.open(dirname + '/' + file)   \n",
    "            img = im.resize((img_rows,img_cols))\n",
    "            #gray = img.convert('L')\n",
    "                        #need to do some more processing here           \n",
    "            img.save(path2 + directory +'/'+subdir+'/' +  file, \"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path1 = os.getcwd()+'/myimages/'\n",
    "path2 = os.getcwd()+'/myimagesresized/'\n",
    "listing = os.listdir(path1) \n",
    "#print(listing)\n",
    "\n",
    "for directory in listing:\n",
    "    print(directory)\n",
    "    if(directory == '.ipynb_checkpoints'):\n",
    "        continue\n",
    "    dirname = (path1+'/'+directory)\n",
    "    dirfiles = os.listdir(dirname)\n",
    "    #print(dirfiles)\n",
    "    for file in dirfiles:\n",
    "        if(file == '.ipynb_checkpoints'):\n",
    "            continue\n",
    "        im = Image.open(dirname + '/' + file)   \n",
    "        img = im.resize((img_rows,img_cols))\n",
    "        #gray = img.convert('L')\n",
    "                    #need to do some more processing here           \n",
    "        img.save(path2 + directory +'/' +  file, \"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imlist = os.listdir(path2+'/acquarium/')\n",
    "\n",
    "im1 = array(Image.open(path2 + '/acquarium/'+ imlist[0])) # open one image to get size\n",
    "m,n = im1.shape[0:2] # get the size of the images\n",
    "imnbr = len(imlist) # get the number of images\n",
    "#print(imnbr)\n",
    "#print(im1)\n",
    "#immatrix = array([array(Image.open(path2 + '/acquarium/' + im2)).flatten() for im2 in imlist],'f')\n",
    "immatrix = np.array([])\n",
    "\n",
    "for image in imlist:\n",
    "    if(image == '.ipynb_checkpoints'):\n",
    "        continue\n",
    "    arry = array(Image.open(path2 + '/acquarium/' + image)).flatten()\n",
    "    #print(arry.shape)\n",
    "    immatrix = np.append(immatrix, arry, axis=0)\n",
    "\n",
    "print(immatrix.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
